{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6f5e48",
   "metadata": {},
   "source": [
    "# Machine Learning Zoomcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0908fc",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaf6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2022fdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c956f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show the information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342540bd",
   "metadata": {},
   "source": [
    "## Data preperation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e35dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145511ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical feature with 'NA'\n",
    "categorical_features = [\n",
    "    'lead_source',\n",
    "    'industry',\n",
    "    'employment_status',\n",
    "    'location'\n",
    "]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    df[feature] = df[feature].fillna('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7e2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numerical feature with 0.0\n",
    "numerical_features = [\n",
    "    'annual_income'\n",
    "]\n",
    "\n",
    "for feature in numerical_features:\n",
    "    df[feature] = df[feature].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbed2c9",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d908368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1462 non-null   object \n",
      " 1   industry                  1462 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1462 non-null   float64\n",
      " 4   employment_status         1462 non-null   object \n",
      " 5   location                  1462 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b84abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18326e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the most frequent observation (mode) for the column industry\n",
    "df['industry'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4cdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer is retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e1a56",
   "metadata": {},
   "source": [
    "##  Question 2\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "    * interaction_count and lead_score\n",
    "    * number_of_courses_viewed and lead_score\n",
    "    * number_of_courses_viewed and interaction_count\n",
    "    * annual_income and interaction_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fc58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'number_of_courses_viewed',\n",
    "    'annual_income',\n",
    "    'interaction_count',\n",
    "    'lead_score',\n",
    "    'converted'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4ae5c",
   "metadata": {},
   "source": [
    "### 2.1 correlation for interaction_count and lead_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8f97bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between interaction_count and lead_score: 0.009888182496913077\n"
     ]
    }
   ],
   "source": [
    "corr_interaction_count_lead_score = df['interaction_count'].corr(df['lead_score'])\n",
    "\n",
    "print(f\"Correlation between interaction_count and lead_score: {corr_interaction_count_lead_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01d9b6",
   "metadata": {},
   "source": [
    "### 2.2 Correlation for number_of_courses_viewed and lead_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac29928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between number_of_courses_viewed and lead_score: -0.00487899835468127\n"
     ]
    }
   ],
   "source": [
    "corr_number_of_courses_viewed_lead_score = df['number_of_courses_viewed'].corr(df['lead_score'])\n",
    "print(f\"Correlation between number_of_courses_viewed and lead_score: {corr_number_of_courses_viewed_lead_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a3f5f",
   "metadata": {},
   "source": [
    "### 2.3 Correlation for number_of_courses_viewed and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33304f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between number_of_courses_viewed and interaction_count: -0.023565222882888103\n"
     ]
    }
   ],
   "source": [
    "corr_number_of_courses_viewed_interaction_count = df['number_of_courses_viewed'].corr(df['interaction_count'])\n",
    "print(f\"Correlation between number_of_courses_viewed and interaction_count: {corr_number_of_courses_viewed_interaction_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723bfca",
   "metadata": {},
   "source": [
    "### 2.4 Coorelation for annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4583e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between annual_income and interaction_count: 0.027036472404814337\n"
     ]
    }
   ],
   "source": [
    "corr_annual_income_interaction_count = df['annual_income'].corr(df['interaction_count'])\n",
    "print(f\"Correlation between annual_income and interaction_count: {corr_annual_income_interaction_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20fae90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest correlation: 0.027036472404814337\n"
     ]
    }
   ],
   "source": [
    "# Get the biggest correlation\n",
    "print(f\"Biggest correlation: {max(corr_interaction_count_lead_score, corr_number_of_courses_viewed_lead_score, corr_number_of_courses_viewed_interaction_count, corr_annual_income_interaction_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5861333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer is annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f22ed",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Which of these variables has the biggest mutual information score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "417e6d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 293, 293)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "full_train_df , test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(full_train_df, test_size=0.25, random_state=42)\n",
    "len(train_df) , len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60aba6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perpare data for modeling\n",
    "target = \"converted\"\n",
    "\n",
    "features = numerical_features + categorical_features\n",
    "features.remove(target)\n",
    "\n",
    "# Training set \n",
    "X_train = train_df[features].reset_index(drop=True)\n",
    "y_train = train_df[target].reset_index(drop=True)\n",
    "\n",
    "# Validation set\n",
    "X_val = val_df[features].reset_index(drop=True)\n",
    "y_val = val_df[target].reset_index(drop=True)\n",
    "\n",
    "# Test set\n",
    "X_test = test_df[features].reset_index(drop=True)\n",
    "y_test = test_df[target].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebffe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def matual_info_sorce_converted(series):\n",
    "    return mutual_info_score(series, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2804654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.035\n",
       "industry             0.012\n",
       "employment_status    0.013\n",
       "location             0.004\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = X_train[categorical_features].apply(matual_info_sorce_converted)\n",
    "mi.sort_values(ascending=False)\n",
    "\n",
    "round(mi, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16f4b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest mutual information score is 0.035 for the feature lead_source\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The biggest mutual information score is {mi.max():.3f} for the feature {mi.idxmax()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73269371",
   "metadata": {},
   "source": [
    "## Queastion 4\n",
    "\n",
    "What accuracy did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec8aec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Accuracy (with all features): 0.6997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# One-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(X_train.to_dict(orient=\"records\"))\n",
    "X_val = dv.transform(X_val.to_dict(orient=\"records\"))\n",
    "X_test = dv.transform(X_test.to_dict(orient=\"records\"))\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape \n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1_000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "converted_decision = y_pred >= 0.5\n",
    "\n",
    "original_accuracy = (converted_decision == y_val).mean()\n",
    "print(f\"Original Model Accuracy (with all features): {original_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c7f5b",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which of following feature has the smallest difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e7418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.8561643835616438\n"
     ]
    }
   ],
   "source": [
    "baseline_acc = accuracy_score(y_val, clf.predict(X_val))\n",
    "print(\"Baseline accuracy:\", baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45479751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model without number_of_courses_viewed| Accuracy = 0.5563| Absolute Difference = 0.1433\n",
      "Model without annual_income           | Accuracy = 0.8532| Absolute Difference = 0.1536\n",
      "Model without interaction_count       | Accuracy = 0.5563| Absolute Difference = 0.1433\n",
      "Model without lead_score              | Accuracy = 0.7065| Absolute Difference = 0.0068\n",
      "Model without lead_source             | Accuracy = 0.7031| Absolute Difference = 0.0034\n",
      "Model without industry                | Accuracy = 0.6997| Absolute Difference = 0.0000\n",
      "Model without employment_status       | Accuracy = 0.6962| Absolute Difference = 0.0034\n",
      "Model without location                | Accuracy = 0.7099| Absolute Difference = 0.0102\n"
     ]
    }
   ],
   "source": [
    "# Store the results in a dictionary\n",
    "accuracy_differences = {}\n",
    "\n",
    "for feature in features:\n",
    "    # Logistic Regression Model\n",
    "    iter_model = LogisticRegression(\n",
    "        solver=\"liblinear\", C=1.0, max_iter=1_000, random_state=42\n",
    "    )\n",
    "\n",
    "    # Features to keep\n",
    "    features_to_keep = [f for f in features if f != feature]\n",
    "\n",
    "    # Training and Validation Set\n",
    "    X_train_iter = train_df[features_to_keep].reset_index(drop=True)\n",
    "    X_val_iter = val_df[features_to_keep].reset_index(drop=True)\n",
    "\n",
    "    dv_iter = DictVectorizer(sparse=False)\n",
    "\n",
    "    # One-hot encoding\n",
    "    X_train_iter = dv_iter.fit_transform(X_train_iter.to_dict(orient=\"records\"))\n",
    "    X_val_iter = dv_iter.transform(X_val_iter.to_dict(orient=\"records\"))\n",
    "\n",
    "    # Training model on subset of features\n",
    "    iter_model.fit(X_train_iter, y_train)\n",
    "\n",
    "    y_pred_iter = iter_model.predict_proba(X_val_iter)[:, 1]\n",
    "    decision_iter = y_pred_iter >= 0.5\n",
    "    iter_accuracy = (decision_iter == y_val).mean()\n",
    "\n",
    "    # Calculate and store the difference\n",
    "    diff = np.abs(original_accuracy - iter_accuracy)\n",
    "    accuracy_differences[feature] = diff\n",
    "\n",
    "    print(\n",
    "        f\"Model without {feature:<24}| Accuracy = {iter_accuracy:.4f}| Absolute Difference = {diff:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b38a25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature is: 'industry'\n"
     ]
    }
   ],
   "source": [
    "# Least useful feature\n",
    "least_useful_feat = min(accuracy_differences, key=accuracy_differences.get)\n",
    "print(f\"The least useful feature is: '{least_useful_feat}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa9124",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Which of these C leads to the best accuracy on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2852460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization parameter: 0.01| Accuracy = 0.700\n",
      "Regularization parameter:  0.1| Accuracy = 0.700\n",
      "Regularization parameter:    1| Accuracy = 0.700\n",
      "Regularization parameter:   10| Accuracy = 0.700\n",
      "Regularization parameter:  100| Accuracy = 0.700\n"
     ]
    }
   ],
   "source": [
    "# Regularization values\n",
    "reg_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "accuracy_reg_values = {}\n",
    "\n",
    "for C in reg_values:\n",
    "    # Logistic Regression\n",
    "    model_reg = LogisticRegression(\n",
    "        solver=\"liblinear\", C=C, max_iter=1_000, random_state=42\n",
    "    )\n",
    "    # Train the model\n",
    "    model_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate predictions\n",
    "    y_pred_reg = model_reg.predict_proba(X_val)[:, 1]\n",
    "    decision_reg = y_pred_reg >= 0.5\n",
    "    reg_accuracy = (decision_reg == y_val).mean()\n",
    "\n",
    "    # Fill the accuracy_reg_values dictionary\n",
    "    accuracy_reg_values[C] = reg_accuracy\n",
    "\n",
    "    print(f\"Regularization parameter: {C:>4}| Accuracy = {reg_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4404e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Regularization parameter is: '0.01'\n"
     ]
    }
   ],
   "source": [
    "# Best regularization parameter\n",
    "best_reg = max(accuracy_reg_values, key=accuracy_reg_values.get)\n",
    "print(f\"The Best Regularization parameter is: '{best_reg}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
